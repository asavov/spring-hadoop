<beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xmlns:batch="http://www.springframework.org/schema/batch" xmlns:hdp="http://www.springframework.org/schema/hadoop"
	xmlns:c="http://www.springframework.org/schema/c" xmlns:p="http://www.springframework.org/schema/p"
	xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd
      	http://www.springframework.org/schema/batch	http://www.springframework.org/schema/batch/spring-batch.xsd
      	http://www.springframework.org/schema/hadoop http://www.springframework.org/schema/hadoop/spring-hadoop.xsd">

	<import resource="../batch-common.xml" />
	<import resource="../hadoop-ctx.xml" />
	
	<hdp:script id="cleanScript" language="javascript" run-at-startup="true">
		if (fsh.test("${hdfs.item.writer.output.dir}")) fsh.rmr("${hdfs.item.writer.output.dir}")
	</hdp:script>	

	<bean id="item-reader" class="org.springframework.batch.item.support.ListItemReader" scope="prototype">
		<constructor-arg>
			<bean class="org.springframework.data.hadoop.serialization.HdfsWriterTest"
				factory-method="createPojoList">
				<constructor-arg
					value="org.springframework.data.hadoop.serialization.HdfsWriterTest.PojoSerializable" />
				<constructor-arg value="100" />
			</bean>
		</constructor-arg>
	</bean>

	<!-- Create Java serialization format -->
	<bean id="javaSerialization" class="org.springframework.data.hadoop.serialization.SequenceFileFormat">
		<constructor-arg
			value="org.springframework.data.hadoop.serialization.HdfsWriterTest.PojoSerializable" />

		<property name="configuration" ref="hadoopConfiguration" />
	</bean>

	<!-- Create Avro serialization format -->
	<bean id="avroSerialization" class="org.springframework.data.hadoop.serialization.AvroFormat">
		<constructor-arg
			value="org.springframework.data.hadoop.serialization.HdfsWriterTest.PojoSerializable" />
	</bean>

	<!-- Create 'write-to-hdfs' service -->
	<bean id="hdfsWriter" class="org.springframework.data.hadoop.serialization.HdfsWriter">
		<constructor-arg ref="hadoopResourceLoader" />

		<property name="serializationFormat" ref="avroSerialization" />
	</bean>

	<!-- Configure a single step jobs writing to hdfs using different completion policies -->

	<!-- Create Batch ItemWriter wrapping 'write-to-hdfs' service -->
	<bean id="hdfs-item-writer-chunks" class="org.springframework.data.hadoop.batch.HdfsItemWriter"
		p:hdfsWriter-ref="hdfsWriter" p:destination="/test/hdfs_item_writer/chunks">

		<property name="destinationSuffixCreator">
			<bean class="org.springframework.batch.item.file.SimpleResourceSuffixCreator" />
		</property>
	</bean>

	<job id="writeToHdfsJob-commit-interval" xmlns="http://www.springframework.org/schema/batch">
		<step id="commit-interval-step">
			<tasklet>
				<chunk reader="item-reader" writer="hdfs-item-writer-chunks" commit-interval="25" />
			</tasklet>
		</step>
	</job>

	<!-- Create Batch ItemWriter wrapping 'write-to-hdfs' service -->
	<bean id="hdfs-item-writer-all" class="org.springframework.data.hadoop.batch.HdfsItemWriter"
		p:hdfsWriter-ref="hdfsWriter" p:destination="/test/hdfs_item_writer/all">
	</bean>

	<bean id="completionPolicy" class="org.springframework.batch.repeat.policy.DefaultResultCompletionPolicy" />

	<job id="writeToHdfsJob-default-completion" xmlns="http://www.springframework.org/schema/batch">
		<step id="default-completion-step">
			<tasklet>
				<chunk reader="item-reader" writer="hdfs-item-writer-all"
					chunk-completion-policy="completionPolicy" />
			</tasklet>
		</step>
	</job>
</beans>